{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import random\n",
    "import sys\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.spatial\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib.gridspec as gridspec\n",
    "# import seaborn as sns\n",
    "import time\n",
    "import csv\n",
    "import math\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img():\n",
    "    im = Image.open(\"/home/lui/catkin_ws/src/FY109-FLP/magnetic_map_data/20191022/map_r1.pgm\")\n",
    "    im.show()\n",
    "    print(im.size)\n",
    "    return im\n",
    "# im = read_img()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data_x = np.genfromtxt('/home/lui/catkin_ws/src/FY109-FLP/magnetic_map_data/20191025/mag_data_x.csv', delimiter=',')\n",
    "my_data_y = np.genfromtxt('/home/lui/catkin_ws/src/FY109-FLP/magnetic_map_data/20191025/mag_data_y.csv', delimiter=',')\n",
    "my_data_z = np.genfromtxt('/home/lui/catkin_ws/src/FY109-FLP/magnetic_map_data/20191025/mag_data_z.csv', delimiter=',')\n",
    "\n",
    "\n",
    "# Load MagImage for deciding that where the data is and getting the width and Height of map\n",
    "def load_image( infilename ) :\n",
    "    img = Image.open( infilename )\n",
    "    img.load()\n",
    "    data = np.asarray( img, dtype=\"int32\" )\n",
    "    return data\n",
    "gray_img = load_image('/home/lui/catkin_ws/src/FY109-FLP/magnetic_map_data/20191025/mag_map.png')\n",
    "(g_height,g_width, channel_size)=gray_img.shape\n",
    "\n",
    "ground_truth_mag_img_x = np.zeros([g_height, g_width])\n",
    "ground_truth_mag_img_y = np.zeros([g_height, g_width])\n",
    "ground_truth_mag_img_z = np.zeros([g_height, g_width])\n",
    "\n",
    "data_xy = []\n",
    "data_z = []\n",
    "\n",
    "max_value = -99\n",
    "min_value = 99\n",
    "abs_min_value = 99\n",
    "\n",
    "mean_x = 0;\n",
    "mean_y = 0;\n",
    "mean_z = 0;\n",
    "\n",
    "for i in range(g_height):\n",
    "    for j in range(g_width):\n",
    "        if gray_img[i][j][0]!=0.0:\n",
    "            if my_data_x[i][j]>max_value:\n",
    "                max_value = my_data_x[i][j]\n",
    "            if my_data_y[i][j]>max_value:\n",
    "                max_value = my_data_y[i][j]\n",
    "            if my_data_z[i][j]>max_value:\n",
    "                max_value = my_data_z[i][j]\n",
    "                \n",
    "            if my_data_x[i][j]<min_value:\n",
    "                min_value = my_data_x[i][j]\n",
    "            if my_data_y[i][j]<min_value:\n",
    "                min_value = my_data_y[i][j]\n",
    "            if my_data_z[i][j]<min_value:\n",
    "                min_value = my_data_z[i][j]\n",
    "            \n",
    "            if abs(my_data_x[i][j])<abs_min_value:\n",
    "                abs_min_value = abs(my_data_x[i][j])\n",
    "            if abs(my_data_y[i][j])<abs_min_value:\n",
    "                abs_min_value = abs(my_data_y[i][j])\n",
    "            if abs(my_data_z[i][j])<abs_min_value:\n",
    "                abs_min_value = abs(my_data_z[i][j])\n",
    "                \n",
    "#             Generate Ground Truth Image\n",
    "            ground_truth_mag_img_x[i][j] = my_data_x[i][j]\n",
    "            ground_truth_mag_img_y[i][j] = my_data_y[i][j]\n",
    "            ground_truth_mag_img_z[i][j] = my_data_z[i][j]\n",
    "            \n",
    "#             Generate training data vec(x,y) & vec(z)\n",
    "            m_mag_vec = []\n",
    "            m_mag_vec.append(my_data_x[i][j])\n",
    "            m_mag_vec.append(my_data_y[i][j])\n",
    "            m_mag_vec.append(my_data_z[i][j])\n",
    "            data_xy.append([j*0.05-3.176096, i*0.05-5.051761]) # (width, height)\n",
    "#             data_xy.append([j, i]) # (width, height)\n",
    "            data_z.append(m_mag_vec)\n",
    "\n",
    "data_xy = np.asarray(data_xy)\n",
    "data_z = np.asarray(data_z)\n",
    "data_size = data_z.shape[0]\n",
    "# print('abs minimal value: ', abs_min_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle data\n",
    "data = np.concatenate((data_xy, data_z), axis=1)\n",
    "np.random.shuffle(data)\n",
    "data_xy, data_z = np.array_split(data, [2], axis=1)\n",
    "\n",
    "# Seperate data to training part and verify part \n",
    "# tmp_size = int(mag_training_data_xy.shape[0]*0.3)\n",
    "# mag_training_data_xy, mag_verify_data_xy = np.array_split(mag_training_data_xy, [tmp_size], axis=0)\n",
    "# mag_training_data_z, mag_verify_data_z = np.array_split(mag_training_data_z, [tmp_size], axis=0)\n",
    "\n",
    "mag_training_data_xy = []\n",
    "mag_training_data_z = []\n",
    "training_data_size = 0\n",
    "\n",
    "def calculate_dist(p1, p2):\n",
    "    return math.hypot(p1[0]-p2[0], p1[1]-p2[1])\n",
    "\n",
    "suitible_flag = False\n",
    "\n",
    "for i in range(data_size):\n",
    "    if training_data_size==0:\n",
    "        mag_training_data_xy.append(data_xy[i])\n",
    "        mag_training_data_z.append(data_z[i])\n",
    "        training_data_size = training_data_size+1\n",
    "    else:\n",
    "        for j in range(training_data_size):\n",
    "            if calculate_dist(data_xy[i], mag_training_data_xy[j]) < 0.1:\n",
    "                break\n",
    "            if j==training_data_size-1:\n",
    "                suitible_flag = True\n",
    "        if suitible_flag:\n",
    "            mag_training_data_xy.append(data_xy[i])\n",
    "            mag_training_data_z.append(data_z[i])\n",
    "            training_data_size = training_data_size+1\n",
    "            suitible_flag = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1413"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Functions may used later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_gp(training_xy, training_z):\n",
    "    kernel = C(0.1, (1e-2, 1e2)) * RBF(10, (1e-2, 1e2))\n",
    "    gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9)\n",
    "\n",
    "    start_time = time.time()\n",
    "    gp.fit(training_xy, training_z)\n",
    "    print(\"---Training Time: %s seconds ---\" % (time.time() - start_time))\n",
    "    return gp\n",
    "\n",
    "def pred_gp(gp, test_xy):\n",
    "    start_time = time.time()\n",
    "    y_pred, sigma = gp.predict(test_xy, return_std=True)\n",
    "    print(\"--- Predict Time:  %s seconds ---\" % (time.time() - start_time))\n",
    "    y_pred = y_pred\n",
    "    return y_pred, sigma\n",
    "\n",
    "def generate_test_data(training_xy):\n",
    "    test_data_range_x =np.linspace(0, g_width-1, g_width)\n",
    "    test_data_range_y =np.linspace(0, g_height-1, g_height)\n",
    "    \n",
    "    test_xy = np.zeros([g_width*g_height,2])\n",
    "    for m in range(g_height):\n",
    "        for n in range(g_width):\n",
    "            test_xy[m*g_width+n][0] = test_data_range_x[n]\n",
    "            test_xy[m*g_width+n][1] = test_data_range_y[m]\n",
    "    return test_xy, g_width, g_height\n",
    "\n",
    "def mark_unknown_area(OneD_pred_map, mark_value):\n",
    "    output = np.zeros(0)\n",
    "\n",
    "    for i in range(g_height):\n",
    "        for j in range(g_width):\n",
    "            if gray_img[i][j][0] ==0.0:\n",
    "                output = np.append(output, mark_value-0.5)\n",
    "            else:\n",
    "                output = np.append(output, OneD_pred_map[i*g_width+j])\n",
    "    return output\n",
    "    \n",
    "def show_predic(test_xy, pred_z,m_axis):\n",
    "    fig, ax = plt.subplots()\n",
    "    _min = min_value\n",
    "    _max = max_value\n",
    "    sc = plt.scatter(test_xy[:,0], test_xy[:,1], c=pred_z, cmap='rainbow', vmin = _min, vmax = _max)\n",
    "    # plt.plot(mag_training_data_xy[:,0], mag_training_data_xy[:,1], 'ko')\n",
    "    # for i in range(len(mag_training_data_z)):\n",
    "    #     ax.annotate(np.round(mag_training_data_z[i],3), xy=(mag_training_data_xy[i][0],mag_training_data_xy[i][1]), color='black', \n",
    "    #             xytext=(5,5), textcoords=\"offset points\")\n",
    "    file_path = \"/home/lui/catkin_ws/src/FY109-FLP/magnetic_map_data/\"\n",
    "    filename = file_path+\"scikit_GP_result_\"+m_axis\n",
    "    plt.colorbar()\n",
    "    plt.savefig(filename)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_xy, data_x_size, data_y_size = generate_test_data(mag_training_data_xy)\n",
    "\n",
    "gp_x = training_gp(mag_training_data_xy, mag_training_data_z[:,0])\n",
    "gp_y = training_gp(mag_training_data_xy, mag_training_data_z[:,1])\n",
    "gp_z = training_gp(mag_training_data_xy, mag_training_data_z[:,2])\n",
    "mag_x_pred, mag_x_sigma = pred_gp()\n",
    "mag_y_pred, mag_y_sigma = training_gp(mag_training_data_xy, mag_training_data_z[:,1])\n",
    "mag_z_pred, mag_z_sigma = training_gp(mag_training_data_xy, mag_training_data_z[:,2])\n",
    "\n",
    "my_draw_test_data_x = test_xy[:,0].reshape(data_x_size*data_y_size,1)\n",
    "my_draw_test_data_y = test_xy[:,1].reshape(data_x_size*data_y_size,1)\n",
    "my_test_predict_zx = mag_x_pred.reshape(data_x_size*data_y_size,1)\n",
    "my_test_predict_zy = mag_y_pred.reshape(data_x_size*data_y_size,1)\n",
    "my_test_predict_zz = mag_z_pred.reshape(data_x_size*data_y_size,1)\n",
    "\n",
    "# # fig, ax = plt.subplots()\n",
    "# # _min, _max = np.amin(mag_training_data_z), np.amax(mag_training_data_z)\n",
    "# # sc = plt.scatter(my_draw_test_data_x, my_draw_test_data_y, c=my_test_predict_zz, cmap='rainbow', vmin = _min, vmax = _max)\n",
    "# # plt.colorbar()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# f, axes = plt.subplots(nrows = 1, ncols = 3, sharex=True, sharey = True)\n",
    "# _min, _max = np.amin(my_test_predict_zx), np.amax(my_test_predict_zx)\n",
    "# sc = axes[0].scatter(my_draw_test_data_x, my_draw_test_data_y, c=my_test_predict_zx, cmap='rainbow', vmin = _min, vmax = _max)\n",
    "# _min, _max = np.amin(my_test_predict_zy), np.amax(my_test_predict_zy)\n",
    "# axes[1].scatter(my_draw_test_data_x, my_draw_test_data_y, c=my_test_predict_zy, cmap='rainbow', vmin = _min, vmax = _max)\n",
    "# _min, _max = np.amin(my_test_predict_zz), np.amax(my_test_predict_zz)\n",
    "# axes[2].scatter(my_draw_test_data_x, my_draw_test_data_y, c=my_test_predict_zz, cmap='rainbow', vmin = _min, vmax = _max)\n",
    "# f.colorbar(sc)\n",
    "show_predic(test_xy, mag_x_pred, 'x')\n",
    "show_predic(test_xy, mag_y_pred, 'y')\n",
    "show_predic(test_xy, mag_z_pred, 'z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_x_pred = mag_x_pred.reshape(g_height, g_width)\n",
    "mag_y_pred = mag_y_pred.reshape(g_height, g_width)\n",
    "mag_z_pred = mag_z_pred.reshape(g_height, g_width)\n",
    "\n",
    "def remove_none_detection_area(mag_pred):\n",
    "    for i in range(g_height):\n",
    "        for j in range(g_width):\n",
    "            if abs(mag_pred[i][j]) < abs_min_value*0.1:\n",
    "                mag_pred[i][j] = 0.0\n",
    "    return mag_pred\n",
    "\n",
    "mag_x_pred = remove_none_detection_area(mag_x_pred)\n",
    "mag_y_pred = remove_none_detection_area(mag_y_pred)\n",
    "mag_z_pred = remove_none_detection_area(mag_z_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"/home/lui/catkin_ws/src/FY109-FLP/magnetic_map_data/predic/mag_pred_x.csv\", mag_x_pred, delimiter=\",\")\n",
    "np.savetxt(\"/home/lui/catkin_ws/src/FY109-FLP/magnetic_map_data/predic/mag_pred_y.csv\", mag_y_pred, delimiter=\",\")\n",
    "np.savetxt(\"/home/lui/catkin_ws/src/FY109-FLP/magnetic_map_data/predic/mag_pred_z.csv\", mag_z_pred, delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Mean Square Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error = 0\n",
    "\n",
    "# for i in range(g_height):\n",
    "#     for j in range(g_width):\n",
    "#         if gray_img[i][j][0]!=0.0:\n",
    "#             error = error + abs(ground_truth_mag_img_x[i][j] - mag_x_pred[i][j])\n",
    "from sklearn.metrics import mean_squared_error \n",
    "MSE = mean_squared_error(ground_truth_mag_img_x,mag_x_pred) \n",
    "print('X axis average error: ', MSE)\n",
    "MSE = mean_squared_error(ground_truth_mag_img_y,mag_y_pred) \n",
    "print('Y axis average error: ', MSE)\n",
    "MSE = mean_squared_error(ground_truth_mag_img_z,mag_z_pred) \n",
    "print('Z axis average error: ', MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ROS_occupied_map(pred_map):\n",
    "    for i in range(g_height):\n",
    "        for j in range(g_width):\n",
    "            if pred_map[i][j]!= 0:\n",
    "                pred_map[i][j] = (pred_map[i][j]-min_value)/(max_value-min_value)*255\n",
    "            else:\n",
    "                pred_map[i][j]=-1\n",
    "    return pred_map\n",
    "\n",
    "mag_x_pred = generate_ROS_occupied_map(mag_x_pred)\n",
    "mag_y_pred = generate_ROS_occupied_map(mag_y_pred)\n",
    "mag_z_pred = generate_ROS_occupied_map(mag_z_pred)\n",
    "np.savetxt(\"/home/lui/catkin_ws/src/FY109-FLP/magnetic_map_data/ROS_msg/mag_pred_x.csv\", mag_x_pred, delimiter=\",\")\n",
    "np.savetxt(\"/home/lui/catkin_ws/src/FY109-FLP/magnetic_map_data/ROS_msg/mag_pred_y.csv\", mag_y_pred, delimiter=\",\")\n",
    "np.savetxt(\"/home/lui/catkin_ws/src/FY109-FLP/magnetic_map_data/ROS_msg/mag_pred_z.csv\", mag_z_pred, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(mag_x_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
